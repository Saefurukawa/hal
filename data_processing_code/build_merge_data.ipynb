{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2061\n",
      "2061\n",
      "{'miss': 477, 'hit': 1584}\n",
      "0.2314410480349345\n",
      "saved at filtered_merged_5seconds.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import glob \n",
    "import os\n",
    "\n",
    "# Load both CSV files into DataFrames\n",
    "\n",
    "def takeTimecards(extension = \"3seconds.csv\"):\n",
    "    def getdata(timecard_name):\n",
    "        def extract_file(input_directory, timecard_name):\n",
    "            for file_path in glob.glob(os.path.join(input_directory, \"*.csv\")):\n",
    "                if file_path.lower().endswith(timecard_name):\n",
    "                    file = pd.read_csv(file_path)\n",
    "                    return file\n",
    "            else:\n",
    "                print(\"This shouldnt happen\", input_directory)\n",
    "                return\n",
    "            \n",
    "        fixation_directory = \"../data/finalized_data/fixation/\"\n",
    "        saccade_directory = \"../data/finalized_data/saccade_filled/\"\n",
    "        sensor_directory = \"../data/finalized_data/sensor/\"\n",
    "        velocity_directory = \"../data/finalized_data/velocity/\"\n",
    "        fixation_data = extract_file(fixation_directory, timecard_name)\n",
    "        saccade_data = extract_file(saccade_directory, timecard_name)\n",
    "        sensor_data = extract_file(sensor_directory, timecard_name)\n",
    "        velocity_data = extract_file(velocity_directory, timecard_name)\n",
    "        return fixation_data, saccade_data, sensor_data, velocity_data\n",
    "        \n",
    "    def renameColumns(data_list):\n",
    "        new_data_list = []\n",
    "        for data in data_list:\n",
    "            rename_dict = {}\n",
    "            for col in data.columns:\n",
    "                if col.strip().lower()== \"aoi label\":\n",
    "                    rename_dict[col] = \"Label\"\n",
    "                if col.strip().lower() == \"respondent name\":\n",
    "                    rename_dict[col] = \"Respondent\"\n",
    "                if col.strip().lower() == \"bridge\":\n",
    "                    rename_dict[col] = \"Study Name\"\n",
    "            data = data.rename(columns = rename_dict)\n",
    "            new_data_list.append(data)\n",
    "        return new_data_list\n",
    "\n",
    "    def normalize_keys(df):\n",
    "        df[\"Study Name\"] = df[\"Study Name\"].str.strip().str.lower()\n",
    "        df[\"Label\"] = df[\"Label\"].str.strip().str.lower()\n",
    "        return df\n",
    "\n",
    "    fixation_data, saccade_data, sensor_data, velocity_data = getdata(extension)\n",
    "    distance_data = pd.read_csv(\"../data/finalized_data/combined_distance_table.csv\")\n",
    "    data_list = [distance_data, saccade_data, fixation_data, sensor_data]\n",
    "    data_list = renameColumns(data_list)\n",
    "    # distance_data = data_list[0]\n",
    "    # velocity_data = data_list[1]\n",
    "    data_list = [normalize_keys(df) for df in data_list]\n",
    "\n",
    "    # # Find rows that are only in df1\n",
    "    # diff = data_list[0].merge(data_list[1], how='outer', indicator=True).query('_merge == \"left_only\"').drop(columns=['_merge'])\n",
    "    # print(len(diff))\n",
    "    # print(diff)\n",
    "\n",
    "    # diff = data_list[1].merge(data_list[0], how='outer', indicator=True).query('_merge == \"left_only\"').drop(columns=['_merge'])\n",
    "    # print(len(diff))\n",
    "    # print(diff)\n",
    "\n",
    "\n",
    "    # # Perform the merge on common columns\n",
    "    merged_df = reduce(lambda left, right: pd.merge(left, right, on=[\"Study Name\", \"Respondent\", \"Label\"], how='outer'), data_list)\n",
    "    print(len(merged_df))\n",
    " \n",
    "\n",
    "    personal_data = pd.read_csv(\"../data/finalized_data/personal_data_merged.csv\")\n",
    "    final_merged_df = merged_df.merge(personal_data, on = \"Respondent\", how = \"left\")\n",
    "    print(len(final_merged_df))\n",
    "    return final_merged_df\n",
    "\n",
    "    # Save the merged DataFrame to a new CSV file\n",
    "    # final_merged_df.to_csv(f'../data/merged_data/merged_data_{extension}', index=False)\n",
    "    # print(f\"Saved at merged_data_{extension}\")\n",
    "    \n",
    "# Load the CSV file into a DataFrame\n",
    "def filterData(df, extension, directory_name):\n",
    "    # df = pd.read_csv(f'../data/merged_data/merged_data_{extension}',keep_default_na=False)\n",
    "    df = df.drop(\"Study Name\", axis='columns')\n",
    "    df = df.drop(\"Respondent\", axis='columns')\n",
    "    df.drop(df[df['Label'].str.contains(\"Base\", na=False)].index, inplace=True)\n",
    "\n",
    "    # drop \"Start\" and \"End\" columns\n",
    "    df = df.drop([\"Start\", \"End\"], axis=1, errors=\"ignore\")\n",
    "    \n",
    "    #drop distance for no-distance\n",
    "    df = df.drop([\"Distance\"], axis=1, errors=\"ignore\")\n",
    "\n",
    "\n",
    "    label_count = {}\n",
    "    label_count[\"miss\"] = 0\n",
    "    label_count[\"hit\"] = 0\n",
    "    for index, row in df.iterrows():\n",
    "        aoi_label = row[\"Label\"].lower()\n",
    "        if \"hit\" in aoi_label:\n",
    "            df.loc[index, 'Label'] = 0\n",
    "            label_count[\"hit\"] +=1\n",
    "        elif \"miss\" in aoi_label:\n",
    "            df.loc[index, 'Label'] = 1\n",
    "            label_count[\"miss\"] +=1\n",
    "        else: #shouldnt happen\n",
    "            print(aoi_label)\n",
    "\n",
    "    print(label_count)\n",
    "    print(label_count[\"miss\"]/(label_count['miss'] + label_count['hit']))\n",
    "\n",
    "    df.to_csv(f\"../data/merged_data/{directory_name}/filtered_merged_{extension}\", index=False)\n",
    "    print(f\"saved at filtered_merged_{extension}\")\n",
    "\n",
    "time = \"5seconds.csv\"\n",
    "directory_name = \"no_distance\"\n",
    "final_merged_df = takeTimecards(time)\n",
    "filterData(final_merged_df, time, directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c229cd6ff87d19ea7d47541bfa1b62a250f965db58eb2430f02bd66bc83489c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
