{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = \"../data/distance_data/\"\n",
    "timecard_path = \"../data/timecards/combined_timecard_3seconds.csv\"\n",
    "output_file = \"../data/combined_distance_table.csv\"\n",
    "\n",
    "# Load the timecard CSV\n",
    "timecard_df = pd.read_csv(timecard_path)\n",
    "\n",
    "# Prepare the timecard for case-insensitive matching\n",
    "timecard_df[\"Lowercase Label\"] = timecard_df[\"Label\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crack 1 Hit\n",
      "[('Bridge 3', 20002, 'crack 4'), ('Bridge 3', 20002, 'crack 18'), ('Bridge 3', 20009, 'crack 12'), ('Bridge 3', 20016, 'crack 10'), ('Bridge 3', 20023, 'crack 18'), ('Bridge 3', 20026, 'crack 10'), ('Bridge 3', 20027, 'crack 10'), ('Bridge 3', 20027, 'crack 16'), ('Bridge 3', 20032, 'crack 10'), ('Bridge 3', 20036, 'crack 18'), ('Bridge 3', 20036, 'crack 20'), ('Bridge 3', 20037, 'crack 18'), ('Bridge 3', 20044, 'crack 5'), ('Bridge 4', 20004, 'crack 14'), ('Bridge 4', 20006, 'crack 16'), ('Bridge 4', 20009, 'crack 15'), ('Bridge 4', 20009, 'crack 16'), ('Bridge 4', 20010, 'crack 14'), ('Bridge 4', 20010, 'crack 15'), ('Bridge 4', 20015, 'crack 16'), ('Bridge 4', 20016, 'crack 10'), ('Bridge 4', 20017, 'crack 11'), ('Bridge 4', 20017, 'crack 15'), ('Bridge 4', 20017, 'crack 18'), ('Bridge 4', 20021, 'crack 13'), ('Bridge 4', 20021, 'crack 17'), ('Bridge 4', 20022, 'crack 14'), ('Bridge 4', 20023, 'crack 13'), ('Bridge 4', 20023, 'crack 14'), ('Bridge 4', 20024, 'crack 12'), ('Bridge 4', 20024, 'crack 16'), ('Bridge 4', 20025, 'crack 16'), ('Bridge 4', 20025, 'crack 18'), ('Bridge 4', 20026, 'crack 13'), ('Bridge 4', 20026, 'crack 14'), ('Bridge 4', 20026, 'crack 15'), ('Bridge 4', 20026, 'crack 16'), ('Bridge 4', 20027, 'crack 11'), ('Bridge 4', 20027, 'crack 12'), ('Bridge 4', 20027, 'crack 13'), ('Bridge 4', 20027, 'crack 14'), ('Bridge 4', 20027, 'crack 15'), ('Bridge 4', 20029, 'crack 10'), ('Bridge 4', 20029, 'crack 15'), ('Bridge 4', 20030, 'crack 10'), ('Bridge 4', 20030, 'crack 11'), ('Bridge 4', 20030, 'crack 12'), ('Bridge 4', 20030, 'crack 16'), ('Bridge 4', 20030, 'crack 17'), ('Bridge 4', 20031, 'crack 15'), ('Bridge 4', 20032, 'crack 13'), ('Bridge 4', 20032, 'crack 15'), ('Bridge 4', 20036, 'crack 14'), ('Bridge 4', 20036, 'crack 15'), ('Bridge 4', 20036, 'crack 16'), ('Bridge 4', 20037, 'crack 6'), ('Bridge 4', 20037, 'crack 10'), ('Bridge 4', 20037, 'crack 13'), ('Bridge 4', 20037, 'crack 16'), ('Bridge 4', 20037, 'crack 17'), ('Bridge 4', 20038, 'crack 11'), ('Bridge 4', 20038, 'crack 12'), ('Bridge 4', 20038, 'crack 13'), ('Bridge 4', 20038, 'crack 14'), ('Bridge 4', 20038, 'crack 15'), ('Bridge 4', 20039, 'crack 15'), ('Bridge 4', 20045, 'crack 12'), ('Bridge 4', 20045, 'crack 14'), ('Bridge 4', 20046, 'crack 16'), ('Bridge 1', 20009, 'crack 16'), ('Bridge 1', 20017, 'crack 14'), ('Bridge 1', 20031, 'crack 14'), ('Bridge 1', 20036, 'crack 14'), ('Bridge 1', 20037, 'crack 14'), ('Bridge 1', 20045, 'crack 14'), ('Bridge 2', 20002, 'crack 17'), ('Bridge 2', 20008, 'crack 8'), ('Bridge 2', 20008, 'crack 17'), ('Bridge 2', 20009, 'crack 9'), ('Bridge 2', 20009, 'crack 17'), ('Bridge 2', 20009, 'crack 18'), ('Bridge 2', 20010, 'crack 17'), ('Bridge 2', 20012, 'crack 20'), ('Bridge 2', 20013, 'crack 20'), ('Bridge 2', 20017, 'crack 1'), ('Bridge 2', 20017, 'crack 14'), ('Bridge 2', 20021, 'crack 8'), ('Bridge 2', 20021, 'crack 17'), ('Bridge 2', 20023, 'crack 1'), ('Bridge 2', 20023, 'crack 9'), ('Bridge 2', 20023, 'crack 17'), ('Bridge 2', 20029, 'crack 17'), ('Bridge 2', 20030, 'crack 17'), ('Bridge 2', 20033, 'crack 1'), ('Bridge 2', 20033, 'crack 11'), ('Bridge 2', 20033, 'crack 17'), ('Bridge 2', 20036, 'crack 9'), ('Bridge 2', 20036, 'crack 17'), ('Bridge 2', 20037, 'crack 9'), ('Bridge 2', 20037, 'crack 10'), ('Bridge 2', 20037, 'crack 11'), ('Bridge 2', 20037, 'crack 17'), ('Bridge 2', 20038, 'crack 20')]\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rows = []\n",
    "dropped_rows = []\n",
    "def getBridgeName(file_path):\n",
    "    if \"Easy 1\" in file_path:\n",
    "        return \"Bridge 1\"\n",
    "    if \"Easy 2\" in file_path:\n",
    "        return \"Bridge 2\"\n",
    "    if \"Hard 1\" in file_path:\n",
    "        return \"Bridge 3\"\n",
    "    if \"Hard 2\" in file_path:\n",
    "        return \"Bridge 4\"\n",
    "    return \"Unknown Bridge\"\n",
    "    \n",
    "# Iterate over each file in the directory\n",
    "for file_path in glob.glob(os.path.join(input_directory, \"*.csv\")):\n",
    "    df = pd.read_csv(file_path, skiprows=0, keep_default_na=False)\n",
    "    bridge = getBridgeName(file_path)  # Derive bridge name from file name\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        respondent = int(row[\"Respondent Name\"])\n",
    "        \n",
    "        # Iterate over crack-related columns\n",
    "        for col in df.columns:\n",
    "            if col.startswith(\"crack\") and row[col] != \"\":\n",
    "                try:\n",
    "                    distance = float(row[col])  # Get the value for this crack\n",
    "                except ValueError:\n",
    "                    continue  # Skip if the value is invalid\n",
    "                \n",
    "                # Prepare for matching\n",
    "                crack_name = col.lower()  # Convert to lowercase for case-insensitive matching\n",
    "                \n",
    "                matched_row = timecard_df[\n",
    "                    (timecard_df[\"Study Name\"] == bridge) &\n",
    "                    (timecard_df[\"Respondent\"] == respondent) &\n",
    "                    (timecard_df[\"Lowercase Label\"].str.contains(rf'\\b{re.escape(crack_name)}\\b', na=False, regex=True))\n",
    "                ]\n",
    "                # Replace AOI Label with matched Label\n",
    "                if not matched_row.empty:\n",
    "                    aoi_label = matched_row[\"Label\"].values[0]  # Use the matched label from timecard\n",
    "                    if bridge == \"Bridge 2\" and respondent == 20024 and crack_name == \"crack 1\":\n",
    "                        print(aoi_label)\n",
    "                    \n",
    "                    # Append the new row to the transformed data\n",
    "                    rows.append({\n",
    "                        \"Study Name\": bridge,\n",
    "                        \"Respondent Name\": respondent,\n",
    "                        \"Label\": aoi_label,  # Use the column name as the AOI Label\n",
    "                        \"Distance\": distance\n",
    "                    })\n",
    "                \n",
    "                else:\n",
    "                    dropped_rows.append((bridge, respondent, col))\n",
    "                    continue\n",
    "                    # aoi_label = col  # Keep the original label if no match\n",
    "                    # print(bridge, respondent, col)\n",
    "                    \n",
    "                \n",
    "\n",
    "# Create a new DataFrame from the transformed data\n",
    "df = pd.DataFrame(rows)\n",
    "print(dropped_rows)\n",
    "print(len(dropped_rows))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of conditions to omit\n",
    "omit_conditions = [\n",
    "    (df[\"Label\"].str.contains(\"Crack 3\")) & (df[\"Study Name\"] == \"Bridge 1\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 3\")) & (df[\"Study Name\"] == \"Bridge 2\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 10\")) & (df[\"Study Name\"] == \"Bridge 2\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 14\")) & (df[\"Study Name\"] == \"Bridge 2\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 15\")) & (df[\"Study Name\"] == \"Bridge 2\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 19\")) & (df[\"Study Name\"] == \"Bridge 2\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 4\")) & (df[\"Study Name\"] == \"Bridge 3\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 5\")) & (df[\"Study Name\"] == \"Bridge 3\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 17\")) & (df[\"Study Name\"] == \"Bridge 3\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 20\")) & (df[\"Study Name\"] == \"Bridge 3\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 4\")) & (df[\"Study Name\"] == \"Bridge 4\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 15\")) & (df[\"Study Name\"] == \"Bridge 4\"),\n",
    "    (df[\"Label\"].str.contains(\"Crack 16\")) & (df[\"Study Name\"] == \"Bridge 4\")\n",
    "]\n",
    "\n",
    "# Combine all conditions with OR\n",
    "combined_condition = omit_conditions[0]\n",
    "for condition in omit_conditions[1:]:\n",
    "    combined_condition |= condition\n",
    "\n",
    "# Omit rows based on combined conditions\n",
    "df_filtered = df[~combined_condition]\n",
    "\n",
    "df_filtered.to_csv(\"../data/finalized_data/combined_distance_table.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15 (main, Oct  3 2024, 02:33:33) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2c229cd6ff87d19ea7d47541bfa1b62a250f965db58eb2430f02bd66bc83489c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
