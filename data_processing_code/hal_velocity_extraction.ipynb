{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Bdk5Jtir_r6"
   },
   "source": [
    "### tidy participant data \n",
    "extract info from txt file\n",
    "convert to csv with time, and velocities in xyz directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TyRb03odoe0l"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "# convert txt controller input file to csv with time and velocity extracted\n",
    "# input: path to txt, path to generated csv\n",
    "def txt_to_csv(txt_file, csv_file):\n",
    "    with open(txt_file, 'r') as file, open(csv_file, 'w', newline='') as csv_out:\n",
    "        writer = csv.writer(csv_out)\n",
    "        writer.writerow(['time', 'x', 'y', 'z', 'Magnitude'])  # Write CSV header\n",
    "\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                result = extract_time_and_velocity(line)\n",
    "                if result:\n",
    "                    time_value, x, y, z = result\n",
    "                    if x == 0 and y == 0 and z == 0:\n",
    "                        continue  # Skip lines with zero velocity\n",
    "                    magnitude = (x**2 + y**2 + z**2)**0.5\n",
    "                    writer.writerow([time_value, x, y, z, magnitude])\n",
    "\n",
    "# helper function to extract the time and velocity values from each line\n",
    "# input: line of csv\n",
    "# output: extraced values\n",
    "def extract_time_and_velocity(line):\n",
    "    # Use a regular expression to capture time and velocity components\n",
    "    time_match = re.search(r'Time:\\s*([0-9.]+)', line)\n",
    "    velocity_match = re.search(r'Velocity:\\s*\\(([^,]+),\\s*([^,]+),\\s*([^)]+)\\)', line)\n",
    "\n",
    "    if time_match and velocity_match:\n",
    "        time_value = float(time_match.group(1))\n",
    "        x, y, z = velocity_match.groups()\n",
    "        return time_value, float(x), float(y), float(z)\n",
    "    return NotImplemented\n",
    "\n",
    "\n",
    "\n",
    "# # Example usage\n",
    "# txt_file = 'data.txt'  # Path to your txt file\n",
    "# csv_file = 'cleaned_data.csv'  # Output CSV file\n",
    "\n",
    "# txt_to_csv(txt_file, csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJw-cF1wsGNe"
   },
   "source": [
    "### apply spline\n",
    "Get dataset with time, velocity, acceleration, jerk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IScD7IoQwt4X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# smooth velocity points over time \n",
    "# input: path to generated csv file\n",
    "def spline(csv_file):\n",
    "  # Load the CSV data\n",
    "  data = pd.read_csv('cleaned_data.csv') # results of txt_to_csv\n",
    "  time = data['time'].values\n",
    "  velocity = data['Magnitude'].values\n",
    "\n",
    "  # Fit a spline to the filtered velocity data\n",
    "  # s value controls degree of smoothing\n",
    "  spline = UnivariateSpline(time, velocity, s=1)\n",
    "\n",
    "  # Compute the first and second derivative of the spline (acceleration, jerk)\n",
    "  acceleration = spline.derivative(n=1)(time)\n",
    "  jerk = spline.derivative(n=2)(time)\n",
    "\n",
    "  data[\"Acceleration\"] = acceleration\n",
    "  data[\"Jerk\"] = jerk\n",
    "\n",
    "  data.to_csv(csv_file, index=False)\n",
    "\n",
    "# # Example Usage\n",
    "# spline('cleaned_data.csv', 'smoothed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laldkdRLs0jb"
   },
   "source": [
    "### plotting \n",
    "ignore:: only used to test univariate spline + include figures in paper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "DJQt2950r2Vn",
    "outputId": "067400e4-d283-4b6a-92d5-3c0d5754ab68"
   },
   "outputs": [],
   "source": [
    "# Plot the original data, smoothed spline, and derived acceleration\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the smoothed velocity data\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(time, velocity, 'o', label='Original Velocity Data')\n",
    "plt.plot(time, spline(time), '-', label='Smoothed Spline')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Velocity')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the acceleration data\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(time, acceleration, label='Acceleration (First Derivative)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Acceleration')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the jerk data\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(time, jerk, label='Jerk (Second Derivative)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Jerk')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLlccJOnLTFl"
   },
   "source": [
    "### Combine & run spline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "XwwGh_p-FWnY"
   },
   "outputs": [],
   "source": [
    "def smooth_participant(input, output):\n",
    "  # convert txt to csv & smooth data\n",
    "  txt_to_csv(input, 'cleaned_data.csv')\n",
    "  spline('cleaned_data.csv', output)\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYRr4sgvlvFw"
   },
   "outputs": [],
   "source": [
    "# run for every file in every bridge folder\n",
    "easy1 = os.listdir('easy1')\n",
    "easy2 = os.listdir('easy2')\n",
    "hard1 = os.listdir('hard1')\n",
    "hard2 = os.listdir('hard2')\n",
    "\n",
    "for file in easy1:\n",
    "  input = 'easy1/' + file\n",
    "  participant_name = file[:-4]\n",
    "  output = 'easy1_smoothed/' + participant_name + '.csv'\n",
    "  smooth_participant(input, output)\n",
    "\n",
    "for file in easy2:\n",
    "  input = 'easy2/' + file\n",
    "  participant_name = file[:-4]\n",
    "  output = 'easy2_smoothed/' + participant_name + '.csv'\n",
    "  smooth_participant(input, output)\n",
    "  \n",
    "for file in hard1:\n",
    "  input = 'hard1/' + file\n",
    "  participant_name = file[:-4]\n",
    "  output = 'hard1_smoothed/' + participant_name + '.csv'\n",
    "  smooth_participant(input, output)\n",
    "\n",
    "for file in hard2:\n",
    "  input = 'hard2/' + file\n",
    "  participant_name = file[:-4]\n",
    "  output = 'hard2_smoothed/' + participant_name + '.csv'\n",
    "  smooth_participant(input, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import timecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Study Name</th>\n",
       "      <th>Respondent</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>681604.76</td>\n",
       "      <td>684604.76</td>\n",
       "      <td>Screen recording 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>105236.07</td>\n",
       "      <td>108236.07</td>\n",
       "      <td>Crack 1 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>113953.90</td>\n",
       "      <td>116953.90</td>\n",
       "      <td>Crack 2 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>129727.52</td>\n",
       "      <td>132727.52</td>\n",
       "      <td>Crack 3 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>140906.03</td>\n",
       "      <td>143906.03</td>\n",
       "      <td>Crack 4 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>147468.52</td>\n",
       "      <td>149968.52</td>\n",
       "      <td>Crack 5 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>170255.04</td>\n",
       "      <td>173255.04</td>\n",
       "      <td>Base 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>225519.07</td>\n",
       "      <td>228519.07</td>\n",
       "      <td>Crack 12 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>244836.19</td>\n",
       "      <td>247836.19</td>\n",
       "      <td>Base 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>249000.86</td>\n",
       "      <td>250800.86</td>\n",
       "      <td>Crack 11 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>256844.65</td>\n",
       "      <td>259844.65</td>\n",
       "      <td>Crack 9 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>265643.80</td>\n",
       "      <td>268643.80</td>\n",
       "      <td>Crack 10 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>270814.35</td>\n",
       "      <td>273814.35</td>\n",
       "      <td>Crack 8 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>277867.48</td>\n",
       "      <td>280867.48</td>\n",
       "      <td>Crack 7 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>274180.11</td>\n",
       "      <td>277180.11</td>\n",
       "      <td>Crack 6 HIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>334568.34</td>\n",
       "      <td>337218.34</td>\n",
       "      <td>Base 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>363467.15</td>\n",
       "      <td>366003.97</td>\n",
       "      <td>Crack 15 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>372192.95</td>\n",
       "      <td>372492.95</td>\n",
       "      <td>Crack 13 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>403076.40</td>\n",
       "      <td>403414.93</td>\n",
       "      <td>Crack 16 HIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>436243.97</td>\n",
       "      <td>439243.97</td>\n",
       "      <td>Base 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>453281.56</td>\n",
       "      <td>456281.56</td>\n",
       "      <td>Crack 17 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>498242.92</td>\n",
       "      <td>501242.92</td>\n",
       "      <td>Crack 18 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>505557.88</td>\n",
       "      <td>506157.88</td>\n",
       "      <td>Crack 20 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>526217.04</td>\n",
       "      <td>529217.04</td>\n",
       "      <td>Crack 19 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>591857.03</td>\n",
       "      <td>594857.03</td>\n",
       "      <td>Crack 14 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20002</td>\n",
       "      <td>658292.44</td>\n",
       "      <td>661292.44</td>\n",
       "      <td>Base 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>437993.76</td>\n",
       "      <td>440993.76</td>\n",
       "      <td>Screen recording 2-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>127773.89</td>\n",
       "      <td>129523.89</td>\n",
       "      <td>Crack 1 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>131747.04</td>\n",
       "      <td>133797.04</td>\n",
       "      <td>Crack 2 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>143960.97</td>\n",
       "      <td>145360.97</td>\n",
       "      <td>Crack 4 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>147928.17</td>\n",
       "      <td>148178.17</td>\n",
       "      <td>Crack 5 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>201671.22</td>\n",
       "      <td>204671.22</td>\n",
       "      <td>Crack 12 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>212598.28</td>\n",
       "      <td>213148.28</td>\n",
       "      <td>Crack 9 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>217289.73</td>\n",
       "      <td>220289.73</td>\n",
       "      <td>Crack 10 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>220379.18</td>\n",
       "      <td>223379.18</td>\n",
       "      <td>Crack 8 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>226096.79</td>\n",
       "      <td>229096.79</td>\n",
       "      <td>Crack 7 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>227117.07</td>\n",
       "      <td>230117.07</td>\n",
       "      <td>Crack 6 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>289827.25</td>\n",
       "      <td>292827.25</td>\n",
       "      <td>Crack 14 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>295488.03</td>\n",
       "      <td>298238.03</td>\n",
       "      <td>Crack 13 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>314928.01</td>\n",
       "      <td>316928.01</td>\n",
       "      <td>Crack 15 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>351710.09</td>\n",
       "      <td>354710.09</td>\n",
       "      <td>Crack 16 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>373778.78</td>\n",
       "      <td>376778.78</td>\n",
       "      <td>Crack 19 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>404446.36</td>\n",
       "      <td>406746.36</td>\n",
       "      <td>Crack 17 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>414898.51</td>\n",
       "      <td>417648.51</td>\n",
       "      <td>Crack 18 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20003</td>\n",
       "      <td>426382.02</td>\n",
       "      <td>429382.02</td>\n",
       "      <td>Crack 20 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>795637.08</td>\n",
       "      <td>798637.08</td>\n",
       "      <td>Screen recording 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>128602.82</td>\n",
       "      <td>131602.82</td>\n",
       "      <td>Crack 1 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>175838.39</td>\n",
       "      <td>177038.39</td>\n",
       "      <td>Crack 14 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>194907.58</td>\n",
       "      <td>196457.58</td>\n",
       "      <td>Crack 2 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>209582.83</td>\n",
       "      <td>211982.83</td>\n",
       "      <td>Crack 3 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>220573.77</td>\n",
       "      <td>223573.77</td>\n",
       "      <td>Crack 4 Miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>220037.20</td>\n",
       "      <td>223037.20</td>\n",
       "      <td>Crack 5 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>252882.89</td>\n",
       "      <td>255882.89</td>\n",
       "      <td>Crack 19 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>282906.16</td>\n",
       "      <td>285906.16</td>\n",
       "      <td>Base 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>380487.13</td>\n",
       "      <td>383487.13</td>\n",
       "      <td>Crack 17 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>412517.85</td>\n",
       "      <td>415517.85</td>\n",
       "      <td>Base 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>444743.79</td>\n",
       "      <td>444793.79</td>\n",
       "      <td>Crack 20 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>455383.02</td>\n",
       "      <td>455933.02</td>\n",
       "      <td>Crack 18 Hit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>503134.86</td>\n",
       "      <td>506134.86</td>\n",
       "      <td>Crack 16 HIt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Bridge 1</td>\n",
       "      <td>20004</td>\n",
       "      <td>602436.31</td>\n",
       "      <td>603486.31</td>\n",
       "      <td>Crack 13 Hit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Study Name  Respondent      Start        End                 Label\n",
       "0    Bridge 1       20002  681604.76  684604.76    Screen recording 2\n",
       "1    Bridge 1       20002  105236.07  108236.07           Crack 1 Hit\n",
       "2    Bridge 1       20002  113953.90  116953.90           Crack 2 Hit\n",
       "3    Bridge 1       20002  129727.52  132727.52           Crack 3 Hit\n",
       "4    Bridge 1       20002  140906.03  143906.03           Crack 4 Hit\n",
       "5    Bridge 1       20002  147468.52  149968.52           Crack 5 Hit\n",
       "6    Bridge 1       20002  170255.04  173255.04                Base 1\n",
       "7    Bridge 1       20002  225519.07  228519.07          Crack 12 Hit\n",
       "8    Bridge 1       20002  244836.19  247836.19                Base 2\n",
       "9    Bridge 1       20002  249000.86  250800.86          Crack 11 Hit\n",
       "10   Bridge 1       20002  256844.65  259844.65           Crack 9 Hit\n",
       "11   Bridge 1       20002  265643.80  268643.80         Crack 10 Miss\n",
       "12   Bridge 1       20002  270814.35  273814.35          Crack 8 Miss\n",
       "13   Bridge 1       20002  277867.48  280867.48          Crack 7 Miss\n",
       "14   Bridge 1       20002  274180.11  277180.11           Crack 6 HIt\n",
       "15   Bridge 1       20002  334568.34  337218.34                Base 4\n",
       "16   Bridge 1       20002  363467.15  366003.97          Crack 15 Hit\n",
       "17   Bridge 1       20002  372192.95  372492.95          Crack 13 Hit\n",
       "18   Bridge 1       20002  403076.40  403414.93          Crack 16 HIt\n",
       "19   Bridge 1       20002  436243.97  439243.97                Base 5\n",
       "20   Bridge 1       20002  453281.56  456281.56         Crack 17 Miss\n",
       "21   Bridge 1       20002  498242.92  501242.92          Crack 18 Hit\n",
       "22   Bridge 1       20002  505557.88  506157.88          Crack 20 Hit\n",
       "23   Bridge 1       20002  526217.04  529217.04          Crack 19 Hit\n",
       "24   Bridge 1       20002  591857.03  594857.03          Crack 14 Hit\n",
       "25   Bridge 1       20002  658292.44  661292.44                Base 3\n",
       "26   Bridge 1       20003  437993.76  440993.76  Screen recording 2-1\n",
       "27   Bridge 1       20003  127773.89  129523.89           Crack 1 Hit\n",
       "28   Bridge 1       20003  131747.04  133797.04           Crack 2 Hit\n",
       "29   Bridge 1       20003  143960.97  145360.97           Crack 4 Hit\n",
       "30   Bridge 1       20003  147928.17  148178.17           Crack 5 Hit\n",
       "31   Bridge 1       20003  201671.22  204671.22         Crack 12 Miss\n",
       "32   Bridge 1       20003  212598.28  213148.28           Crack 9 Hit\n",
       "33   Bridge 1       20003  217289.73  220289.73         Crack 10 Miss\n",
       "34   Bridge 1       20003  220379.18  223379.18          Crack 8 Miss\n",
       "35   Bridge 1       20003  226096.79  229096.79          Crack 7 Miss\n",
       "36   Bridge 1       20003  227117.07  230117.07           Crack 6 Hit\n",
       "37   Bridge 1       20003  289827.25  292827.25         Crack 14 Miss\n",
       "38   Bridge 1       20003  295488.03  298238.03          Crack 13 Hit\n",
       "39   Bridge 1       20003  314928.01  316928.01         Crack 15 Miss\n",
       "40   Bridge 1       20003  351710.09  354710.09         Crack 16 Miss\n",
       "41   Bridge 1       20003  373778.78  376778.78          Crack 19 Hit\n",
       "42   Bridge 1       20003  404446.36  406746.36         Crack 17 Miss\n",
       "43   Bridge 1       20003  414898.51  417648.51         Crack 18 Miss\n",
       "44   Bridge 1       20003  426382.02  429382.02          Crack 20 Hit\n",
       "65   Bridge 1       20004  795637.08  798637.08    Screen recording 2\n",
       "66   Bridge 1       20004  128602.82  131602.82           Crack 1 Hit\n",
       "67   Bridge 1       20004  175838.39  177038.39          Crack 14 Hit\n",
       "68   Bridge 1       20004  194907.58  196457.58           Crack 2 Hit\n",
       "69   Bridge 1       20004  209582.83  211982.83           Crack 3 Hit\n",
       "70   Bridge 1       20004  220573.77  223573.77          Crack 4 Miss\n",
       "71   Bridge 1       20004  220037.20  223037.20           Crack 5 Hit\n",
       "72   Bridge 1       20004  252882.89  255882.89          Crack 19 Hit\n",
       "73   Bridge 1       20004  282906.16  285906.16                Base 1\n",
       "74   Bridge 1       20004  380487.13  383487.13          Crack 17 Hit\n",
       "75   Bridge 1       20004  412517.85  415517.85                Base 5\n",
       "76   Bridge 1       20004  444743.79  444793.79          Crack 20 Hit\n",
       "77   Bridge 1       20004  455383.02  455933.02          Crack 18 Hit\n",
       "78   Bridge 1       20004  503134.86  506134.86          Crack 16 HIt\n",
       "79   Bridge 1       20004  602436.31  603486.31          Crack 13 Hit"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the timecard file and split by bridge\n",
    "times = pd.read_csv('timecards/combined_timecard_3seconds.csv')\n",
    "\n",
    "times = times.dropna(subset=['Start'])\n",
    "times = times[~times[\"Label\"].astype(str).str.contains(\"Base\", case=False, na=False)]\n",
    "times = times[~times[\"Label\"].astype(str).str.contains(\"FA\", case=False, na=False)]\n",
    "\n",
    "easy1_times = times[times['Study Name'] == 'Bridge 1']\n",
    "easy2_times = times[times['Study Name'] == 'Bridge 2']\n",
    "hard1_times = times[times['Study Name'] == 'Bridge 3']\n",
    "hard2_times = times[times['Study Name'] == 'Bridge 4']\n",
    "\n",
    "easy1_times.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate for each bridge \n",
    "this section is very much not modular :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "easy1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'avg_velocity'] = filtered_data['Magnitude'].mean()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'sd_velocity'] = filtered_data['Magnitude'].std()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'med_velocity'] = filtered_data['Magnitude'].median()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'avg_acceleration'] = filtered_data['Acceleration'].mean()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'sd_acceleration'] = filtered_data['Acceleration'].std()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'med_acceleration'] = filtered_data['Acceleration'].median()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'avg_jerk'] = filtered_data['Jerk'].mean()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'sd_jerk'] = filtered_data['Jerk'].std()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.at[index, 'med_jerk'] = filtered_data['Jerk'].median()\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3771727691.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy1_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# adjust time based on recording start time\n",
    "adjust = 0\n",
    "\n",
    "# Iterate through each row in easy1_times\n",
    "for index, row in easy1_times.iterrows():\n",
    "    respondent = row['Respondent']\n",
    "    start_time = row['Start']\n",
    "    end_time = row['End']\n",
    "    # first row of bridge gives time to adjust\n",
    "    if row['Label'][0:16] == 'Screen recording':\n",
    "      adjust = row['Start']\n",
    "\n",
    "    # Construct the file path for the participant's CSV file\n",
    "    file_path = f'smoothed/easy1_smoothed/{respondent}.csv'\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the participant's CSV file\n",
    "        participant_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Filter the data between the start and end times\n",
    "        # adjust for milliseconds & start time\n",
    "        filtered_data = participant_data[(participant_data['time'] >= (start_time-adjust)/1000) & (participant_data['time'] <= (end_time-adjust)/1000)]\n",
    "\n",
    "        # If there is no data for the time interval, skip row\n",
    "        if filtered_data.empty:\n",
    "            continue\n",
    "\n",
    "        # calculate and append the results to the timecard\n",
    "        easy1_times.at[index, 'avg_velocity'] = filtered_data['Magnitude'].mean()\n",
    "        easy1_times.at[index, 'sd_velocity'] = filtered_data['Magnitude'].std()\n",
    "        easy1_times.at[index, 'med_velocity'] = filtered_data['Magnitude'].median()\n",
    "        easy1_times.at[index, 'avg_acceleration'] = filtered_data['Acceleration'].mean()\n",
    "        easy1_times.at[index, 'sd_acceleration'] = filtered_data['Acceleration'].std()\n",
    "        easy1_times.at[index, 'med_acceleration'] = filtered_data['Acceleration'].median()\n",
    "        easy1_times.at[index, 'avg_jerk'] = filtered_data['Jerk'].mean()\n",
    "        easy1_times.at[index, 'sd_jerk'] = filtered_data['Jerk'].std()\n",
    "        easy1_times.at[index, 'med_jerk'] = filtered_data['Jerk'].median()\n",
    "    else:\n",
    "        # If the participant file does not exist, append a NaN or default value\n",
    "        easy1_times.at[index, 'avg_velocity'] = None\n",
    "        easy1_times.at[index, 'sd_velocity'] = None\n",
    "        easy1_times.at[index, 'med_velocity'] = None\n",
    "        easy1_times.at[index, 'avg_acceleration'] = None\n",
    "        easy1_times.at[index, 'sd_acceleration'] = None\n",
    "        easy1_times.at[index, 'med_acceleration'] = None\n",
    "        easy1_times.at[index, 'avg_jerk'] = None\n",
    "        easy1_times.at[index, 'sd_jerk'] = None\n",
    "        easy1_times.at[index, 'med_jerk'] = None\n",
    "\n",
    "# drop irrelevant labels\n",
    "easy1_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n",
    "\n",
    "# Save the updated easy1_times.csv file\n",
    "easy1_times.to_csv('easy1_velocities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat for easy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'avg_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'sd_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'med_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'avg_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'sd_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'med_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'avg_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'sd_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.at[index, 'med_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/1836664867.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  easy2_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "adjust = 0\n",
    "\n",
    "# Iterate through each row in easy2_times\n",
    "for index, row in easy2_times.iterrows():\n",
    "    respondent = row['Respondent']\n",
    "    start_time = row['Start']\n",
    "    end_time = row['End']\n",
    "    if row['Label'][0:16] == 'Screen recording':\n",
    "      adjust = row['Start']\n",
    "\n",
    "    # Construct the file path for the participant's CSV file\n",
    "    file_path = f'easy2_smoothed/{respondent}.csv'\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the participant's CSV file\n",
    "        participant_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Filter the data between the start and end times\n",
    "        filtered_data = participant_data[(participant_data['time'] >= (start_time-adjust)/1000) & (participant_data['time'] <= (end_time-adjust)/1000)]\n",
    "\n",
    "        # If there is no data for the time interval, skip row\n",
    "        if filtered_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Append the results to the list\n",
    "        easy2_times.at[index, 'avg_velocity'] = filtered_data['Magnitude'].mean()\n",
    "        easy2_times.at[index, 'sd_velocity'] = filtered_data['Magnitude'].std()\n",
    "        easy2_times.at[index, 'med_velocity'] = filtered_data['Magnitude'].median()\n",
    "        easy2_times.at[index, 'avg_acceleration'] = filtered_data['Acceleration'].mean()\n",
    "        easy2_times.at[index, 'sd_acceleration'] = filtered_data['Acceleration'].std()\n",
    "        easy2_times.at[index, 'med_acceleration'] = filtered_data['Acceleration'].median()\n",
    "        easy2_times.at[index, 'avg_jerk'] = filtered_data['Jerk'].mean()\n",
    "        easy2_times.at[index, 'sd_jerk'] = filtered_data['Jerk'].std()\n",
    "        easy2_times.at[index, 'med_jerk'] = filtered_data['Jerk'].median()\n",
    "    else:\n",
    "        # If the participant file does not exist, append a NaN or default value\n",
    "        easy2_times.at[index, 'avg_velocity'] = None\n",
    "        easy2_times.at[index, 'sd_velocity'] = None\n",
    "        easy2_times.at[index, 'med_velocity'] = None\n",
    "        easy2_times.at[index, 'avg_acceleration'] = None\n",
    "        easy2_times.at[index, 'sd_acceleration'] = None\n",
    "        easy2_times.at[index, 'med_acceleration'] = None\n",
    "        easy2_times.at[index, 'avg_jerk'] = None\n",
    "        easy2_times.at[index, 'sd_jerk'] = None\n",
    "        easy2_times.at[index, 'med_jerk'] = None\n",
    "\n",
    "easy2_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n",
    "\n",
    "# Save the updated easy1_times.csv file\n",
    "easy2_times.to_csv('easy2_velocities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat for hard 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'avg_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'sd_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'med_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'avg_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'sd_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'med_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'avg_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'sd_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.at[index, 'med_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/121251973.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard1_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "adjust = 0\n",
    "\n",
    "# Iterate through each row in hard1_times\n",
    "for index, row in hard1_times.iterrows():\n",
    "    respondent = row['Respondent']\n",
    "    start_time = row['Start']\n",
    "    end_time = row['End']\n",
    "    if row['Label'][0:16] == 'Screen recording':\n",
    "      adjust = row['Start']\n",
    "\n",
    "    # Construct the file path for the participant's CSV file\n",
    "    file_path = f'hard1_smoothed/{respondent}.csv'\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the participant's CSV file\n",
    "        participant_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Filter the data between the start and end times\n",
    "        filtered_data = participant_data[(participant_data['time'] >= (start_time-adjust)/1000) & (participant_data['time'] <= (end_time-adjust)/1000)]\n",
    "\n",
    "        # If there is no data for the time interval, skip row\n",
    "        if filtered_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Append the results to the list\n",
    "        hard1_times.at[index, 'avg_velocity'] = filtered_data['Magnitude'].mean()\n",
    "        hard1_times.at[index, 'sd_velocity'] = filtered_data['Magnitude'].std()\n",
    "        hard1_times.at[index, 'med_velocity'] = filtered_data['Magnitude'].median()\n",
    "        hard1_times.at[index, 'avg_acceleration'] = filtered_data['Acceleration'].mean()\n",
    "        hard1_times.at[index, 'sd_acceleration'] = filtered_data['Acceleration'].std()\n",
    "        hard1_times.at[index, 'med_acceleration'] = filtered_data['Acceleration'].median()\n",
    "        hard1_times.at[index, 'avg_jerk'] = filtered_data['Jerk'].mean()\n",
    "        hard1_times.at[index, 'sd_jerk'] = filtered_data['Jerk'].std()\n",
    "        hard1_times.at[index, 'med_jerk'] = filtered_data['Jerk'].median()\n",
    "    else:\n",
    "        # If the participant file does not exist, append a NaN or default value\n",
    "        hard1_times.at[index, 'avg_velocity'] = None\n",
    "        hard1_times.at[index, 'sd_velocity'] = None\n",
    "        hard1_times.at[index, 'med_velocity'] = None\n",
    "        hard1_times.at[index, 'avg_acceleration'] = None\n",
    "        hard1_times.at[index, 'sd_acceleration'] = None\n",
    "        hard1_times.at[index, 'med_acceleration'] = None\n",
    "        hard1_times.at[index, 'avg_jerk'] = None\n",
    "        hard1_times.at[index, 'sd_jerk'] = None\n",
    "        hard1_times.at[index, 'med_jerk'] = None\n",
    "\n",
    "hard1_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n",
    "\n",
    "# Save the updated easy1_times.csv file\n",
    "hard1_times.to_csv('hard1_velocities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat for hard2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'avg_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'sd_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'med_velocity'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'avg_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'sd_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'med_acceleration'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'avg_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'sd_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.at[index, 'med_jerk'] = None\n",
      "/var/folders/gb/s6qcw0vn3q14trwzv15zhvtm0000gn/T/ipykernel_5556/3695327388.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hard2_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n"
     ]
    }
   ],
   "source": [
    "adjust = 0\n",
    "\n",
    "# Iterate through each row in hard2_times\n",
    "for index, row in hard2_times.iterrows():\n",
    "    respondent = row['Respondent']\n",
    "    start_time = row['Start']\n",
    "    end_time = row['End']\n",
    "    if row['Label'][0:16] == 'Screen recording':\n",
    "      adjust = row['Start']\n",
    "\n",
    "    # Construct the file path for the participant's CSV file\n",
    "    file_path = f'hard2_smoothed/{respondent}.csv'\n",
    "\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(file_path):\n",
    "        # Load the participant's CSV file\n",
    "        participant_data = pd.read_csv(file_path)\n",
    "\n",
    "        # Filter the data between the start and end times\n",
    "        filtered_data = participant_data[(participant_data['time'] >= (start_time-adjust)/1000) & (participant_data['time'] <= (end_time-adjust)/1000)]\n",
    "\n",
    "        # If there is no data for the time interval, skip row\n",
    "        if filtered_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Append the results to the list\n",
    "        hard2_times.at[index, 'avg_velocity'] = filtered_data['Magnitude'].mean()\n",
    "        hard2_times.at[index, 'sd_velocity'] = filtered_data['Magnitude'].std()\n",
    "        hard2_times.at[index, 'med_velocity'] = filtered_data['Magnitude'].median()\n",
    "        hard2_times.at[index, 'avg_acceleration'] = filtered_data['Acceleration'].mean()\n",
    "        hard2_times.at[index, 'sd_acceleration'] = filtered_data['Acceleration'].std()\n",
    "        hard2_times.at[index, 'med_acceleration'] = filtered_data['Acceleration'].median()\n",
    "        hard2_times.at[index, 'avg_jerk'] = filtered_data['Jerk'].mean()\n",
    "        hard2_times.at[index, 'sd_jerk'] = filtered_data['Jerk'].std()\n",
    "        hard2_times.at[index, 'med_jerk'] = filtered_data['Jerk'].median()\n",
    "    else:\n",
    "        # If the participant file does not exist, append a NaN or default value\n",
    "        hard2_times.at[index, 'avg_velocity'] = None\n",
    "        hard2_times.at[index, 'sd_velocity'] = None\n",
    "        hard2_times.at[index, 'med_velocity'] = None\n",
    "        hard2_times.at[index, 'avg_acceleration'] = None\n",
    "        hard2_times.at[index, 'sd_acceleration'] = None\n",
    "        hard2_times.at[index, 'med_acceleration'] = None\n",
    "        hard2_times.at[index, 'avg_jerk'] = None\n",
    "        hard2_times.at[index, 'sd_jerk'] = None\n",
    "        hard2_times.at[index, 'med_jerk'] = None\n",
    "\n",
    "hard2_times.drop(columns=['Start', 'End'], inplace=True, axis=1)\n",
    "\n",
    "# Save the updated easy1_times.csv file\n",
    "hard2_times.to_csv('hard2_velocities.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine bridges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy1 = pd.read_csv('easy1_velocities.csv')\n",
    "easy2 = pd.read_csv('easy2_velocities.csv')\n",
    "hard1 = pd.read_csv('hard1_velocities.csv')\n",
    "hard2 = pd.read_csv('hard2_velocities.csv')\n",
    "\n",
    "easy1['Study Name'] = \"Bridge 1\"\n",
    "easy2['Study Name'] = \"Bridge 2\"\n",
    "hard1['Study Name'] = \"Bridge 3\"\n",
    "hard2['Study Name'] = \"Bridge 4\"\n",
    "\n",
    "combined = pd.concat([easy1, easy2, hard1, hard2])\n",
    "\n",
    "#Drop rows where they are expliclty omitted\n",
    "combined.drop(combined[(combined[\"Respondent\"]==20019)].index, inplace=True)\n",
    "combined.drop(combined[(combined[\"Respondent\"]==20040)].index, inplace=True)\n",
    "\n",
    "#Drop cracks that are all hit\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 1\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 3 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 2\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 3 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 2\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 10 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 2\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 14 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 2\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 15 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 3\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 4 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 3\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 5 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 3\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 17 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 3\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 20 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 4\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 4 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 4\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 15 hit\", na=False))].index, inplace=True)\n",
    "combined.drop(combined[(combined['Study Name'].str.contains(\"Bridge 4\", na=False)) & (combined['Label'].str.lower().str.contains(\"crack 16 hit\", na=False))].index, inplace=True)\n",
    "\n",
    "\n",
    "combined = combined[~combined[\"Label\"].astype(str).str.contains(\"Screen recording\", case=False, na=False)]\n",
    "\n",
    "combined.to_csv('velocities/velocities_3seconds.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "laldkdRLs0jb"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
